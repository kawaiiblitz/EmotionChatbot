{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOfjzVCJ39SS"
      },
      "source": [
        "# DialoGPT Small\n",
        "Based on the paper: Towards Emotional Support Dialog Systems (https://arxiv.org/abs/2106.01144)\n",
        "\n",
        "codes_zcj is the version reproduced by @chujiezheng. This version was used for this experiment due to its ease of reproducibility.                \n",
        "\n",
        "**0. Preparing Enviroment**\n",
        "\n",
        "conda env create -f env.yml -n cuda\n",
        "conda activate cuda\n",
        "Downloading Model\n",
        "You should **first download the DialoGPT-small model** and replace the fake pytorch_model.bin file in DialoGPT with the true one.\n",
        "\n",
        "If you would like to evaluate generated results with Embedding-based similarity, you can download my prepared embedding files from HuggingFace.\n",
        "\n",
        "**About Postfix**\n",
        "\n",
        "_vanilla denotes the variant directly fine-tuned on ESConv without using strategies\n",
        "_strat denotes the one that additionally uses the strategy information and supervision\n",
        "\n",
        "**1. Preprocessing Training Data**\n",
        "First, enter _reformat and run python process.py.\n",
        "\n",
        "Then, run bash RUN/prepare_vanilla_dialogpt.sh to preprocess the training data.\n",
        "\n",
        "**2. Training Your Model**\n",
        "\n",
        "Run bash RUN/train_vanilla_dialogpt.sh to train your model.\n",
        "\n",
        "**3. Inference with Your Model**\n",
        "\n",
        "Every time of model training will create a new folder in DATA/{inputter_name}.{config_name}, which is named after the time when the training starts. You should select a checkpoint (it may be based on the PPL of validation), and replace the checkpoint path in RUN/infer_vanilla_dialogpt.sh --load_checkpoint with the path of your selected checkpoint.\n",
        "\n",
        "Then, run bash RUN/infer_vanilla_dialogpt.sh to do the inference.\n",
        "\n",
        "Note: When you run infer_strat.sh, you can change GOLDEN_TRUTH in inputters/PARAMS.py to control whether use the golden strategy during inference.\n",
        "\n",
        "**4. Interacting with Your Model**\n",
        "\n",
        "Similar to inference, after designating the checkpoint in RUN/interact_vanilla_dialogpt.sh --load_checkpoint, run bash RUN/interact_vanilla.sh.\n",
        "\n",
        "**Note 1: Reproduction Purposes**\n",
        "For reproduction purposes, you need to:\n",
        "1. Download the files from: https://drive.google.com/drive/folders/1-HhUpWSkLnxiGHMPkqXTjhB7Ak81iTXV?usp=drive_link\n",
        "2. Upload them to the Google Drive content environment.\n",
        "3. Follow the steps described in the previous section.\n",
        "\n",
        "**Note 2: Update function and libraries**\n",
        "Follow the steps from BlenderBot to download GloVe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiTes-rtOtI3",
        "outputId": "8de5c1b8-c24a-4a9e-8c50-0dd833c5a2c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#/content/drive/MyDrive/Emotional-Support-Conversation/codes_zcj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ITodLeTsmiL"
      },
      "outputs": [],
      "source": [
        "# To use the location of the 'EsConv files' in your own Drive\n",
        "!ln -s \"/content/drive/MyDrive/EsConv_v3\" \"/content/Emotional-Support-Conversation\"\n",
        "\n",
        "\n",
        "#/content/Emotional-Support-Conversation/EsConv_v3/codes_zcj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9am-2uM47hz"
      },
      "outputs": [],
      "source": [
        "#!rm -rf /content/Emotional-Support-Conversation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_xV1iaZ49AA"
      },
      "outputs": [],
      "source": [
        "#!ln -s /content/drive/MyDrive/EsConv_v3 /content/Emotional-Support-Conversation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEf8v2xzsoPp",
        "outputId": "13dfd84b-cda8-47fa-af5c-65c68e99fbe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "infer_strat_dialogpt.sh       interact_vanilla.sh\t   train_strat_dialogpt.sh\n",
            "infer_strat.sh\t\t      prepare_strat_dialogpt.sh    train_strat.sh\n",
            "infer_vanilla.sh\t      prepare_strat.sh\t\t   train_vanilla_dialogpt.sh\n",
            "interact_strat.sh\t      prepare_vanilla_dialogpt.sh  train_vanilla.sh\n",
            "interact_vanilla_dialogpt.sh  prepare_vanilla.sh\n"
          ]
        }
      ],
      "source": [
        "# Verify 14 files\n",
        "!ls /content/Emotional-Support-Conversation/codes_zcj/RUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZr4V5G5synz",
        "outputId": "ea2082f2-3b7d-4bbf-df02-9febb8cef5bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Emotional-Support-Conversation/codes_zcj\n"
          ]
        }
      ],
      "source": [
        "%cd Emotional-Support-Conversation/codes_zcj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95VcoFdksnD0",
        "outputId": "3586b989-d442-4dfc-ff08-160f6b3695dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mâœ¨ğŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sAprA45snYG",
        "outputId": "80e78b9d-c716-41c5-e5e8-a573847c252b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Emotional-Support-Conversation/codes_zcj\n",
            "\n",
            "CondaValueError: prefix already exists: /usr/local/envs/cuda\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Emotional-Support-Conversation/codes_zcj\n",
        "!conda env create -f env.yml -n cuda\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W8HP6yMYEXL7",
        "outputId": "97067e32-bf8a-44db-a1ab-c7b6fbf03884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy<2.0,>=1.19.5 (from scikit-learn)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.6.0 (from scikit-learn)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
            "Successfully installed joblib-1.3.2 numpy-1.26.4 scikit-learn-1.4.1.post1 scipy-1.12.0 threadpoolctl-3.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: six\n",
            "Successfully installed six-1.16.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "5b98ab4479d34720894a9094f173ae02",
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/site-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/site-packages (from gensim) (1.12.0)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, smart-open, gensim\n",
            "Successfully installed gensim-4.3.2 smart-open-7.0.4 wrapt-1.16.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting psutil\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psutil\n",
            "Successfully installed psutil-5.9.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install six\n",
        "!pip install gensim\n",
        "!pip install psutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gn2Pnqw_s7Hw",
        "outputId": "f911a3d1-2295-45d1-dca9-59f55c59950d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch)\n",
            "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting mpmath>=0.19 (from sympy->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
            "Downloading filelock-3.13.3-py3-none-any.whl (11 kB)\n",
            "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
            "Successfully installed MarkupSafe-2.1.5 filelock-3.13.3 fsspec-2024.3.1 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.2.1 triton-2.2.0 typing-extensions-4.10.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tokenizers\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting huggingface_hub<1.0,>=0.16.4 (from tokenizers)\n",
            "  Downloading huggingface_hub-0.22.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.3.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Collecting pyyaml>=5.1 (from huggingface_hub<1.0,>=0.16.4->tokenizers)\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.11.17)\n",
            "Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.22.0-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m388.5/388.5 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyyaml, huggingface_hub, tokenizers\n",
            "Successfully installed huggingface_hub-0.22.0 pyyaml-6.0.1 tokenizers-0.15.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting transformers==4.21.0\n",
            "  Downloading transformers-4.21.0-py3-none-any.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers==4.21.0) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.21.0) (0.22.0)\n",
            "Collecting numpy>=1.17 (from transformers==4.21.0)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.21.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers==4.21.0) (6.0.1)\n",
            "Collecting regex!=2019.12.17 (from transformers==4.21.0)\n",
            "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers==4.21.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.21.0)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers==4.21.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.0) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.21.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.21.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.21.0) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.21.0) (2023.11.17)\n",
            "Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, regex, numpy, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "Successfully installed numpy-1.26.4 regex-2023.12.25 tokenizers-0.12.1 transformers-4.21.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "3b4dd085e03b4439866802add7c8dba9",
              "pip_warning": {
                "packages": [
                  "regex"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (4.66.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (1.26.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nltk\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting click (from nltk)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting joblib (from nltk)\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
            "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: joblib, click, nltk\n",
            "Successfully installed click-8.1.7 joblib-1.3.2 nltk-3.8.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "dbe2d8b0362041f7af756a49e1efa234",
              "pip_warning": {
                "packages": [
                  "joblib",
                  "nltk"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install tokenizers\n",
        "!pip install transformers==4.21.0\n",
        "!pip install tqdm\n",
        "!pip install numpy\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTxFCpHdtCZI",
        "outputId": "312da053-231d-4bbf-cd23-5f53423f159a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import\n",
        "import json\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "import nltk\n",
        "import random\n",
        "from collections import Counter\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "# Seed\n",
        "random.seed(13)\n",
        "\n",
        "# punkt tokenizer\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZVS9w4StIaF",
        "outputId": "c16bb727-fc56-4956-968a-f119b3008f6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mâœ¨ğŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "#!pip install -q condacolab\n",
        "#import condacolab\n",
        "#condacolab.install()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwjvGNVatqcG",
        "outputId": "a1d2089c-7a1b-4b5a-8de5-0df854f25ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "EnvironmentFileNotFound: '/content/env.yml' file not found\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!conda env create -f env.yml -n cuda\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8x4ePTsxdDk"
      },
      "outputs": [],
      "source": [
        "!source activate cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAZi6ccVxj65",
        "outputId": "43e6235b-f474-4c36-ca00-633194c56eb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 337M\n",
            "-rw------- 1 root root   554 Mar  6 11:39 config.json\n",
            "-rw------- 1 root root  446K Feb 22 00:41 merges.txt\n",
            "-rw------- 1 root root  335M Mar  5 21:43 pytorch_model.bin\n",
            "-rw------- 1 root root 1018K Feb 22 00:41 vocab.json\n"
          ]
        }
      ],
      "source": [
        "!ls -lh \"/content/Emotional-Support-Conversation/codes_zcj/DialoGPT-small/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltTs9tcCyERB"
      },
      "outputs": [],
      "source": [
        "!sed -i 's|python prepare.py|python /content/Emotional-Support-Conversation/codes_zcj/prepare.py|' /content/Emotional-Support-Conversation/codes_zcj/RUN/prepare_vanilla_dialogpt.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8pyHgCZzVUg",
        "outputId": "51d1dfc9-d68b-4539-faec-528c9e3e7606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking if config exists at: /content/Emotional-Support-Conversation/codes_zcj/CONFIG/vanilla_dialogpt.json\n",
            "Config file found, proceeding to load.\n"
          ]
        }
      ],
      "source": [
        "config_path = '/content/Emotional-Support-Conversation/codes_zcj/CONFIG/vanilla_dialogpt.json'\n",
        "print(f\"Checking if config exists at: {config_path}\")\n",
        "if not os.path.exists(config_path):\n",
        "    raise ValueError(f\"Config file not found at {config_path}\")\n",
        "else:\n",
        "    print(\"Config file found, proceeding to load.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjQW1z-60DH3"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5drjW6wg0FBy",
        "outputId": "286a647b-c963-4fc3-92d0-57f9d7165895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 910/910 [00:06<00:00, 147.75it/s]\n"
          ]
        }
      ],
      "source": [
        "# Preprocess training data\n",
        "!bash /content/Emotional-Support-Conversation/codes_zcj/RUN/prepare_vanilla_dialogpt.sh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48i9eiIi00Wz"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY0n-Nt_a_J2"
      },
      "source": [
        "The weights were downloaded from : https://huggingface.co/microsoft/DialoGPT-small/blob/main/README.md\n",
        "\n",
        "To replace pytorch_model.bin with the one from Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQlWDpM7ben8"
      },
      "outputs": [],
      "source": [
        "# Move from My Drive to the file:\n",
        "#!mv \"/content/drive/MyDrive/pytorch_model.bin\" \"/content/drive/My Drive/Emotional-Support-Conversation/codes_zcj/DialoGPT-small/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVNKM4BjZyIA",
        "outputId": "e1d4d1aa-96a2-4b01-aae5-b353d9023410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model weights file was loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Check\n",
        "# Path to the model weights file\n",
        "model_path = '/content/Emotional-Support-Conversation/codes_zcj/DialoGPT-small/pytorch_model.bin'\n",
        "\n",
        "# Try to load the model state\n",
        "try:\n",
        "    state_dict = torch.load(model_path, map_location='cpu')\n",
        "    print(\"The model weights file was loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading the model weights file: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoOCyJeQ01d_",
        "outputId": "8447e247-cd34-44b8-8b75-43aedd805820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "03/05/2024 23:35:06 - INFO - __main__ -   CUDA available? True\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   train batch size = 16, new train batch size (after gradient accumulation) = 16\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   initializing cuda...\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   Input Argument Information\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   config_name                   vanilla_dialogpt\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   inputter_name                 vanilla\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   seed                          13\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   load_checkpoint               None\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   max_input_length              180\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   max_decoder_input_length      45\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   max_knowledge_len             None\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   label_num                     None\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   only_encode                   False\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   eval_input_file               /content/Emotional-Support-Conversation/codes_zcj/_reformat/valid.txt\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   train_batch_size              16\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   gradient_accumulation_steps   1\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   eval_batch_size               16\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   learning_rate                 5e-05\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   warmup_steps                  100\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   num_optim_steps               20000\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   valid_step                    2000\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   num_epochs                    2\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   max_grad_norm                 1.0\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   fp16                          False\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   loss_scale                    0.0\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   pbar                          True\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   local_rank                    -1\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   config                        None\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   device                        cuda\n",
            "03/05/2024 23:35:06 - INFO - __main__ -   n_gpu                         1\n",
            "03/05/2024 23:35:09 - INFO - utils.building_utils -   deploying model...\n",
            "03/05/2024 23:35:09 - INFO - __main__ -   Number of parameter = 124439808\n",
            "/usr/local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "training:  50% 766/1534 [02:41<02:40,  4.78it/s, ppl: 164.72 epoch: 0]03/05/2024 23:37:54 - INFO - utils.eval_utils -   compute eval model loss, using eval mode, please change it back to train after calling this function\n",
            "\n",
            "validating:   0% 0/195 [00:00<?, ?it/s]\u001b[A\n",
            "validating:   1% 2/195 [00:00<00:13, 14.41it/s]\u001b[A\n",
            "validating:   2% 4/195 [00:00<00:13, 14.13it/s]\u001b[A\n",
            "validating:   3% 6/195 [00:00<00:12, 15.53it/s]\u001b[A\n",
            "validating:   4% 8/195 [00:00<00:11, 16.23it/s]\u001b[A\n",
            "validating:   5% 10/195 [00:00<00:10, 17.06it/s]\u001b[A\n",
            "validating:   6% 12/195 [00:00<00:11, 16.63it/s]\u001b[A\n",
            "validating:   7% 14/195 [00:00<00:12, 14.98it/s]\u001b[A\n",
            "validating:   8% 16/195 [00:01<00:12, 14.54it/s]\u001b[A\n",
            "validating:   9% 18/195 [00:01<00:12, 14.66it/s]\u001b[A\n",
            "validating:  10% 20/195 [00:01<00:11, 15.10it/s]\u001b[A\n",
            "validating:  11% 22/195 [00:01<00:11, 15.25it/s]\u001b[A\n",
            "validating:  13% 25/195 [00:01<00:11, 14.58it/s]\u001b[A\n",
            "validating:  14% 27/195 [00:01<00:11, 14.71it/s]\u001b[A\n",
            "validating:  15% 29/195 [00:01<00:12, 13.80it/s]\u001b[A\n",
            "validating:  16% 31/195 [00:02<00:11, 14.59it/s]\u001b[A\n",
            "validating:  17% 33/195 [00:02<00:10, 15.62it/s]\u001b[A\n",
            "validating:  18% 35/195 [00:02<00:10, 15.16it/s]\u001b[A\n",
            "validating:  19% 37/195 [00:02<00:10, 14.62it/s]\u001b[A\n",
            "validating:  21% 40/195 [00:02<00:10, 14.26it/s]\u001b[A\n",
            "validating:  22% 42/195 [00:02<00:10, 14.32it/s]\u001b[A\n",
            "validating:  23% 44/195 [00:02<00:10, 14.29it/s]\u001b[A\n",
            "validating:  24% 46/195 [00:03<00:09, 15.27it/s]\u001b[A\n",
            "validating:  25% 48/195 [00:03<00:10, 13.56it/s]\u001b[A\n",
            "validating:  26% 50/195 [00:03<00:10, 13.75it/s]\u001b[A\n",
            "validating:  27% 52/195 [00:03<00:10, 13.62it/s]\u001b[A\n",
            "validating:  28% 54/195 [00:03<00:10, 13.28it/s]\u001b[A\n",
            "validating:  29% 56/195 [00:03<00:10, 12.71it/s]\u001b[A\n",
            "validating:  30% 58/195 [00:04<00:10, 13.17it/s]\u001b[A\n",
            "validating:  31% 60/195 [00:04<00:11, 11.86it/s]\u001b[A\n",
            "validating:  32% 63/195 [00:04<00:10, 12.23it/s]\u001b[A\n",
            "validating:  33% 65/195 [00:04<00:10, 12.05it/s]\u001b[A\n",
            "validating:  34% 67/195 [00:04<00:11, 11.34it/s]\u001b[A\n",
            "validating:  35% 69/195 [00:04<00:10, 12.48it/s]\u001b[A\n",
            "validating:  36% 71/195 [00:05<00:09, 12.65it/s]\u001b[A\n",
            "validating:  37% 73/195 [00:05<00:08, 13.95it/s]\u001b[A\n",
            "validating:  38% 75/195 [00:05<00:08, 13.47it/s]\u001b[A\n",
            "validating:  39% 77/195 [00:05<00:08, 13.16it/s]\u001b[A\n",
            "validating:  41% 79/195 [00:05<00:08, 14.29it/s]\u001b[A\n",
            "validating:  42% 81/195 [00:05<00:10, 10.89it/s]\u001b[A\n",
            "validating:  43% 83/195 [00:06<00:09, 11.45it/s]\u001b[A\n",
            "validating:  44% 85/195 [00:06<00:08, 12.56it/s]\u001b[A\n",
            "validating:  45% 87/195 [00:06<00:08, 13.21it/s]\u001b[A\n",
            "validating:  46% 89/195 [00:06<00:07, 14.06it/s]\u001b[A\n",
            "validating:  47% 91/195 [00:06<00:07, 13.89it/s]\u001b[A\n",
            "validating:  48% 93/195 [00:06<00:08, 12.54it/s]\u001b[A\n",
            "validating:  49% 95/195 [00:06<00:07, 14.09it/s]\u001b[A\n",
            "validating:  50% 97/195 [00:07<00:06, 14.16it/s]\u001b[A\n",
            "validating:  51% 99/195 [00:07<00:06, 14.12it/s]\u001b[A\n",
            "validating:  52% 101/195 [00:07<00:08, 11.70it/s]\u001b[A\n",
            "validating:  53% 103/195 [00:07<00:07, 12.42it/s]\u001b[A\n",
            "validating:  54% 105/195 [00:07<00:07, 12.36it/s]\u001b[A\n",
            "validating:  55% 107/195 [00:07<00:06, 13.49it/s]\u001b[A\n",
            "validating:  56% 109/195 [00:07<00:05, 14.38it/s]\u001b[A\n",
            "validating:  57% 111/195 [00:08<00:07, 11.83it/s]\u001b[A\n",
            "validating:  58% 114/195 [00:08<00:05, 15.49it/s]\u001b[A\n",
            "validating:  59% 116/195 [00:08<00:05, 15.75it/s]\u001b[A\n",
            "validating:  61% 118/195 [00:08<00:05, 13.77it/s]\u001b[A\n",
            "validating:  62% 120/195 [00:08<00:06, 11.82it/s]\u001b[A\n",
            "validating:  63% 122/195 [00:08<00:05, 12.71it/s]\u001b[A\n",
            "validating:  64% 124/195 [00:09<00:05, 13.04it/s]\u001b[A\n",
            "validating:  65% 126/195 [00:09<00:05, 13.20it/s]\u001b[A\n",
            "validating:  66% 128/195 [00:09<00:04, 13.81it/s]\u001b[A\n",
            "validating:  67% 130/195 [00:09<00:04, 14.26it/s]\u001b[A\n",
            "validating:  68% 132/195 [00:09<00:04, 14.08it/s]\u001b[A\n",
            "validating:  69% 134/195 [00:09<00:04, 14.01it/s]\u001b[A\n",
            "validating:  70% 136/195 [00:09<00:04, 14.17it/s]\u001b[A\n",
            "validating:  71% 138/195 [00:10<00:04, 14.06it/s]\u001b[A\n",
            "validating:  72% 140/195 [00:10<00:03, 13.85it/s]\u001b[A\n",
            "validating:  73% 142/195 [00:10<00:04, 12.54it/s]\u001b[A\n",
            "validating:  74% 144/195 [00:10<00:03, 13.36it/s]\u001b[A\n",
            "validating:  75% 146/195 [00:10<00:03, 13.52it/s]\u001b[A\n",
            "validating:  76% 148/195 [00:10<00:03, 14.84it/s]\u001b[A\n",
            "validating:  77% 150/195 [00:10<00:03, 13.70it/s]\u001b[A\n",
            "validating:  78% 152/195 [00:11<00:02, 14.40it/s]\u001b[A\n",
            "validating:  79% 154/195 [00:11<00:03, 11.88it/s]\u001b[A\n",
            "validating:  81% 157/195 [00:11<00:02, 14.30it/s]\u001b[A\n",
            "validating:  82% 159/195 [00:11<00:02, 14.51it/s]\u001b[A\n",
            "validating:  83% 161/195 [00:11<00:02, 15.01it/s]\u001b[A\n",
            "validating:  84% 163/195 [00:11<00:02, 16.00it/s]\u001b[A\n",
            "validating:  85% 165/195 [00:12<00:02, 13.86it/s]\u001b[A\n",
            "validating:  86% 167/195 [00:12<00:02, 13.39it/s]\u001b[A\n",
            "validating:  87% 169/195 [00:12<00:02, 12.12it/s]\u001b[A\n",
            "validating:  88% 171/195 [00:12<00:01, 12.67it/s]\u001b[A\n",
            "validating:  89% 173/195 [00:12<00:01, 12.72it/s]\u001b[A\n",
            "validating:  90% 175/195 [00:12<00:01, 12.08it/s]\u001b[A\n",
            "validating:  91% 177/195 [00:13<00:01, 12.75it/s]\u001b[A\n",
            "validating:  92% 179/195 [00:13<00:01, 12.15it/s]\u001b[A\n",
            "validating:  93% 181/195 [00:13<00:01, 12.18it/s]\u001b[A\n",
            "validating:  94% 183/195 [00:13<00:00, 13.42it/s]\u001b[A\n",
            "validating:  95% 185/195 [00:13<00:00, 14.14it/s]\u001b[A\n",
            "validating:  96% 187/195 [00:13<00:00, 14.35it/s]\u001b[A\n",
            "validating:  97% 189/195 [00:13<00:00, 14.11it/s]\u001b[A\n",
            "validating:  98% 191/195 [00:14<00:00, 11.38it/s]\u001b[A\n",
            "validating:  99% 193/195 [00:14<00:00, 10.21it/s]\u001b[A\n",
            "validating: 100% 195/195 [00:14<00:00, 13.41it/s]\n",
            "\n",
            " Epoch 0: Val loss 2.9616806507110596 Val ppl 19.330432891845703 \n",
            "03/05/2024 23:38:09 - INFO - __main__ -   current learning rate: 2.6778242677824267e-05\n",
            "training: 100% 1531/1534 [05:37<00:00,  4.86it/s, ppl: 18.39 epoch: 1]03/05/2024 23:40:51 - INFO - utils.eval_utils -   compute eval model loss, using eval mode, please change it back to train after calling this function\n",
            "\n",
            "validating:   0% 0/195 [00:00<?, ?it/s]\u001b[A\n",
            "validating:   1% 2/195 [00:00<00:10, 17.98it/s]\u001b[A\n",
            "validating:   2% 4/195 [00:00<00:12, 15.71it/s]\u001b[A\n",
            "validating:   3% 6/195 [00:00<00:11, 16.53it/s]\u001b[A\n",
            "validating:   4% 8/195 [00:00<00:10, 17.02it/s]\u001b[A\n",
            "validating:   5% 10/195 [00:00<00:10, 17.79it/s]\u001b[A\n",
            "validating:   6% 12/195 [00:00<00:10, 17.19it/s]\u001b[A\n",
            "validating:   7% 14/195 [00:00<00:11, 15.54it/s]\u001b[A\n",
            "validating:   8% 16/195 [00:01<00:12, 14.87it/s]\u001b[A\n",
            "validating:   9% 18/195 [00:01<00:11, 15.07it/s]\u001b[A\n",
            "validating:  10% 20/195 [00:01<00:11, 15.53it/s]\u001b[A\n",
            "validating:  11% 22/195 [00:01<00:11, 15.50it/s]\u001b[A\n",
            "validating:  13% 25/195 [00:01<00:11, 14.78it/s]\u001b[A\n",
            "validating:  14% 27/195 [00:01<00:11, 14.96it/s]\u001b[A\n",
            "validating:  15% 29/195 [00:01<00:11, 14.22it/s]\u001b[A\n",
            "validating:  16% 31/195 [00:02<00:11, 14.85it/s]\u001b[A\n",
            "validating:  17% 33/195 [00:02<00:10, 15.94it/s]\u001b[A\n",
            "validating:  18% 35/195 [00:02<00:10, 15.52it/s]\u001b[A\n",
            "validating:  19% 37/195 [00:02<00:10, 15.32it/s]\u001b[A\n",
            "validating:  21% 40/195 [00:02<00:10, 15.31it/s]\u001b[A\n",
            "validating:  22% 42/195 [00:02<00:09, 15.52it/s]\u001b[A\n",
            "validating:  23% 44/195 [00:02<00:09, 15.72it/s]\u001b[A\n",
            "validating:  24% 47/195 [00:03<00:10, 13.98it/s]\u001b[A\n",
            "validating:  25% 49/195 [00:03<00:10, 14.45it/s]\u001b[A\n",
            "validating:  26% 51/195 [00:03<00:09, 14.64it/s]\u001b[A\n",
            "validating:  27% 53/195 [00:03<00:09, 14.61it/s]\u001b[A\n",
            "validating:  28% 55/195 [00:03<00:09, 14.28it/s]\u001b[A\n",
            "validating:  29% 57/195 [00:03<00:09, 14.05it/s]\u001b[A\n",
            "validating:  30% 59/195 [00:03<00:09, 14.99it/s]\u001b[A\n",
            "validating:  31% 61/195 [00:04<00:10, 12.73it/s]\u001b[A\n",
            "validating:  32% 63/195 [00:04<00:10, 12.41it/s]\u001b[A\n",
            "validating:  33% 65/195 [00:04<00:10, 12.27it/s]\u001b[A\n",
            "validating:  34% 67/195 [00:04<00:11, 11.15it/s]\u001b[A\n",
            "validating:  35% 69/195 [00:04<00:10, 12.40it/s]\u001b[A\n",
            "validating:  36% 71/195 [00:04<00:10, 12.19it/s]\u001b[A\n",
            "validating:  37% 73/195 [00:05<00:08, 13.61it/s]\u001b[A\n",
            "validating:  38% 75/195 [00:05<00:09, 12.80it/s]\u001b[A\n",
            "validating:  39% 77/195 [00:05<00:09, 12.67it/s]\u001b[A\n",
            "validating:  41% 79/195 [00:05<00:08, 14.00it/s]\u001b[A\n",
            "validating:  42% 81/195 [00:05<00:10, 11.18it/s]\u001b[A\n",
            "validating:  43% 83/195 [00:05<00:09, 11.58it/s]\u001b[A\n",
            "validating:  44% 85/195 [00:06<00:08, 12.57it/s]\u001b[A\n",
            "validating:  45% 87/195 [00:06<00:08, 12.32it/s]\u001b[A\n",
            "validating:  46% 89/195 [00:06<00:09, 11.78it/s]\u001b[A\n",
            "validating:  47% 91/195 [00:06<00:08, 11.71it/s]\u001b[A\n",
            "validating:  48% 93/195 [00:06<00:09, 10.44it/s]\u001b[A\n",
            "validating:  49% 95/195 [00:06<00:08, 11.53it/s]\u001b[A\n",
            "validating:  50% 97/195 [00:07<00:08, 11.69it/s]\u001b[A\n",
            "validating:  51% 99/195 [00:07<00:07, 12.13it/s]\u001b[A\n",
            "validating:  52% 101/195 [00:07<00:09,  9.71it/s]\u001b[A\n",
            "validating:  53% 103/195 [00:07<00:08, 10.30it/s]\u001b[A\n",
            "validating:  54% 105/195 [00:07<00:08, 10.30it/s]\u001b[A\n",
            "validating:  55% 107/195 [00:08<00:07, 11.58it/s]\u001b[A\n",
            "validating:  56% 109/195 [00:08<00:06, 12.58it/s]\u001b[A\n",
            "validating:  57% 111/195 [00:08<00:07, 11.48it/s]\u001b[A\n",
            "validating:  58% 113/195 [00:08<00:06, 13.16it/s]\u001b[A\n",
            "validating:  59% 115/195 [00:08<00:05, 13.89it/s]\u001b[A\n",
            "validating:  60% 117/195 [00:08<00:06, 12.42it/s]\u001b[A\n",
            "validating:  61% 119/195 [00:08<00:05, 12.97it/s]\u001b[A\n",
            "validating:  62% 121/195 [00:09<00:05, 14.20it/s]\u001b[A\n",
            "validating:  63% 123/195 [00:09<00:04, 14.49it/s]\u001b[A\n",
            "validating:  64% 125/195 [00:09<00:04, 14.57it/s]\u001b[A\n",
            "validating:  65% 127/195 [00:09<00:04, 14.55it/s]\u001b[A\n",
            "validating:  66% 129/195 [00:09<00:04, 14.95it/s]\u001b[A\n",
            "validating:  67% 131/195 [00:09<00:04, 14.87it/s]\u001b[A\n",
            "validating:  68% 133/195 [00:09<00:04, 14.50it/s]\u001b[A\n",
            "validating:  69% 135/195 [00:10<00:04, 14.14it/s]\u001b[A\n",
            "validating:  70% 137/195 [00:10<00:04, 14.06it/s]\u001b[A\n",
            "validating:  71% 139/195 [00:10<00:04, 13.93it/s]\u001b[A\n",
            "validating:  72% 141/195 [00:10<00:04, 11.25it/s]\u001b[A\n",
            "validating:  73% 143/195 [00:10<00:04, 12.82it/s]\u001b[A\n",
            "validating:  74% 145/195 [00:10<00:03, 13.49it/s]\u001b[A\n",
            "validating:  75% 147/195 [00:11<00:04, 11.38it/s]\u001b[A\n",
            "validating:  76% 149/195 [00:11<00:04, 11.44it/s]\u001b[A\n",
            "validating:  77% 151/195 [00:11<00:03, 12.34it/s]\u001b[A\n",
            "validating:  78% 153/195 [00:11<00:03, 13.30it/s]\u001b[A\n",
            "validating:  79% 155/195 [00:11<00:02, 13.79it/s]\u001b[A\n",
            "validating:  81% 157/195 [00:11<00:02, 13.97it/s]\u001b[A\n",
            "validating:  82% 159/195 [00:11<00:02, 14.13it/s]\u001b[A\n",
            "validating:  83% 161/195 [00:12<00:02, 14.76it/s]\u001b[A\n",
            "validating:  84% 163/195 [00:12<00:02, 15.86it/s]\u001b[A\n",
            "validating:  85% 165/195 [00:12<00:02, 13.90it/s]\u001b[A\n",
            "validating:  86% 167/195 [00:12<00:02, 13.70it/s]\u001b[A\n",
            "validating:  87% 169/195 [00:12<00:02, 12.58it/s]\u001b[A\n",
            "validating:  88% 171/195 [00:12<00:01, 13.14it/s]\u001b[A\n",
            "validating:  89% 173/195 [00:12<00:01, 13.20it/s]\u001b[A\n",
            "validating:  90% 175/195 [00:13<00:01, 12.28it/s]\u001b[A\n",
            "validating:  91% 177/195 [00:13<00:01, 12.84it/s]\u001b[A\n",
            "validating:  92% 179/195 [00:13<00:01, 12.07it/s]\u001b[A\n",
            "validating:  93% 181/195 [00:13<00:01, 12.04it/s]\u001b[A\n",
            "validating:  94% 183/195 [00:13<00:00, 13.31it/s]\u001b[A\n",
            "validating:  95% 185/195 [00:13<00:00, 14.03it/s]\u001b[A\n",
            "validating:  96% 187/195 [00:13<00:00, 14.24it/s]\u001b[A\n",
            "validating:  97% 189/195 [00:14<00:00, 13.86it/s]\u001b[A\n",
            "validating:  98% 191/195 [00:14<00:00, 11.21it/s]\u001b[A\n",
            "validating:  99% 193/195 [00:14<00:00, 10.30it/s]\u001b[A\n",
            "validating: 100% 195/195 [00:14<00:00, 13.22it/s]\n",
            "\n",
            " Epoch 1: Val loss 2.9239678382873535 Val ppl 18.61500358581543 \n",
            "03/05/2024 23:41:05 - INFO - __main__ -   current learning rate: 6.97350069735007e-08\n",
            "training: 100% 1532/1534 [05:54<00:00,  4.32it/s, ppl: 18.39 epoch: 1]\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "#!chmod +x /content/Emotional-Support-Conversation/codes_zcj/RUN/train_vanilla.sh\n",
        "!bash /content/Emotional-Support-Conversation/codes_zcj/RUN/train_vanilla_dialogpt.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQzuVftBzKm6",
        "outputId": "c8638db1-8aa6-4db8-bea8-7599ca3cedb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "#%cd /content/drive/MyDrive/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w90Jj4K-rhXF",
        "outputId": "dbe30622-3291-4fbf-bda2-7a3cb0b69520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot create symbolic link '/content/drive/MyDrive/EsConvDialog/Emotional-Support-Conversation': Operation not supported\n"
          ]
        }
      ],
      "source": [
        "# To save the files in My Drive\n",
        "#!cp -r /content/Emotional-Support-Conversation /content/drive/MyDrive/EsConvDialog\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XDP1KxaB2sF"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVkDFlJF4p6r",
        "outputId": "4d48f361-060f-4834-a738-1763888438b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "03/07/2024 15:08:55 - INFO - __main__ -   initializing cuda...\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   Input Argument Information\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   config_name                   vanilla_dialogpt\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   inputter_name                 vanilla\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   seed                          0\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   load_checkpoint               /content/Emotional-Support-Conversation/codes_zcj/DATA/vanilla.vanilla_dialogpt/2024-03-05233511.5e-05.16.1gpu/epoch-1.bin\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   fp16                          False\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   max_input_length              180\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   max_src_turn                  None\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   max_decoder_input_length      45\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   max_knowledge_length          None\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   label_num                     None\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   multi_knl                     False\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   only_encode                   False\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   only_generate                 False\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   chinese                       False\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   add_nlg_eval                  True\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   min_length                    10\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   max_length                    45\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   num_return_sequences          1\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   infer_batch_size              16\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   infer_input_file              ['/content/Emotional-Support-Conversation/codes_zcj/_reformat/test.txt']\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   temperature                   0.7\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   top_k                         0\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   top_p                         0.9\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   num_beams                     1\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   length_penalty                1.0\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   repetition_penalty            1.0\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   no_repeat_ngram_size          3\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   device                        cuda\n",
            "03/07/2024 15:08:55 - INFO - __main__ -   n_gpu                         1\n",
            "03/07/2024 15:08:57 - INFO - utils.building_utils -   loading finetuned model from /content/Emotional-Support-Conversation/codes_zcj/DATA/vanilla.vanilla_dialogpt/2024-03-05233511.5e-05.16.1gpu/epoch-1.bin\n",
            "03/07/2024 15:09:03 - INFO - utils.building_utils -   deploying model...\n",
            "03/07/2024 15:09:03 - INFO - __main__ -   Number of parameter = 124439808\n",
            "{\n",
            "  \"max_length\": 45,\n",
            "  \"min_length\": 10,\n",
            "  \"do_sample\": true,\n",
            "  \"temperature\": 0.7,\n",
            "  \"top_k\": 0,\n",
            "  \"top_p\": 0.9,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"encoder_no_repeat_ngram_size\": null,\n",
            "  \"pad_token_id\": 50256,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256\n",
            "}\n",
            "03/07/2024 15:09:04 - INFO - utils.eval_utils -   compute eval model loss, using eval mode, please change it back to train after calling this function\n",
            "validating: 100% 195/195 [00:15<00:00, 12.36it/s]\n",
            "\n",
            " Epoch 0: Val loss 2.9930191040039062 Val ppl 19.945810317993164 \n",
            "inferring: 100% 195/195 [02:18<00:00,  1.41it/s]\n",
            "03/07/2024 15:11:46 - INFO - gensim.models.keyedvectors -   loading projection weights from /content/Emotional-Support-Conversation/codes_zcj/metric/word2vector/english/glove6B/glove.6B.300d.word2vec.bin\n",
            "03/07/2024 15:12:00 - INFO - gensim.utils -   KeyedVectors lifecycle event {'msg': 'loaded (400000, 300) matrix of type float32 from /content/Emotional-Support-Conversation/codes_zcj/metric/word2vector/english/glove6B/glove.6B.300d.word2vec.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2024-03-07T15:12:00.579880', 'gensim': '4.3.2', 'python': '3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0]', 'platform': 'Linux-6.1.58+-x86_64-with-glibc2.35', 'event': 'load_word2vec_format'}\n"
          ]
        }
      ],
      "source": [
        "!bash /content/Emotional-Support-Conversation/codes_zcj/RUN/infer_vanilla_dialogpt.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBMlOzjHc-8a"
      },
      "outputs": [],
      "source": [
        "#/content/Emotional-Support-Conversation/codes_zcj/infer.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQi1BMJKHdSb"
      },
      "source": [
        "## Interact with the chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SdrXjUEntok"
      },
      "outputs": [],
      "source": [
        "#!chmod +x /content/Emotional-Support-Conversation/codes_zcj/RUN/interact_vanilla_dialogpt.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash /content/drive/MyDrive/EsConv_v3/codes_zcj/RUN/interact_vanilla_dialogpt.sh"
      ],
      "metadata": {
        "id": "5oteZqq8EHb0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}